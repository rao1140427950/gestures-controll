# gestures-controll
Use tensorflow to train a network and recognize gestures. Then use the gestures to control the computer.<br/>
Basically, the model can recognize 6 different gestures showing in the below:<br/>
![Image Text](https://github.com/rao1140427950/gestures-controll/blob/srcs/001.png)<br/>
![Image Text](https://github.com/rao1140427950/gestures-controll/blob/srcs/002.png)<br/>
![Image Text](https://github.com/rao1140427950/gestures-controll/blob/srcs/003.png)<br/>
![Image Text](https://github.com/rao1140427950/gestures-controll/blob/srcs/004.png)<br/>
![Image Text](https://github.com/rao1140427950/gestures-controll/blob/srcs/005.png)<br/>
![Image Text](https://github.com/rao1140427950/gestures-controll/blob/srcs/006.png)<br/>
<br/>
Then the model will remember the changes of gestures and the movement of hand. And for specific gestures combined with specific movement, the model will do some control to the computer, such as click, double click, move the mouse, etc.<br/>
Also, the forPi.py can be run on a Raspberry pi to do gestures recognition. The fps on the Pi is about 5.</br>
